{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Probability for Data Science\n",
                "This notebook provides a comprehensive overview of probability topics essential for data science, including mathematical formulations and Python code examples. Each section covers a key topic with explanations, math, and practical implementations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Basic Probability Concepts\n",
                "### 1.1 Sample Space and Events\n",
                "**Explanation**: The sample space (Ω) is the set of all possible outcomes of an experiment. An event is a subset of the sample space.\n",
                "\n",
                "**Math**:\n",
                "- Sample space: Ω = {all possible outcomes}\n",
                "- Event A ⊆ Ω\n",
                "- Probability of event A: P(A) = |A| / |Ω| (for finite, equally likely outcomes)\n",
                "\n",
                "**Example**: Rolling a fair six-sided die."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# Sample space for a six-sided die\n",
                "sample_space = np.array([1, 2, 3, 4, 5, 6])\n",
                "# Event: rolling an even number\n",
                "event_even = sample_space[sample_space % 2 == 0]\n",
                "prob_even = len(event_even) / len(sample_space)\n",
                "print(f\"Sample space: {sample_space}\")\n",
                "print(f\"Event (even numbers): {event_even}\")\n",
                "print(f\"Probability of even number: {prob_even}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 Probability Rules\n",
                "**Explanation**: Key rules include the addition rule, multiplication rule, and conditional probability.\n",
                "\n",
                "**Math**:\n",
                "- Addition rule: P(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n",
                "- Multiplication rule: P(A ∩ B) = P(A) * P(B|A) if A and B are dependent\n",
                "- Conditional probability: P(A|B) = P(A ∩ B) / P(B), where P(B) > 0\n",
                "\n",
                "**Example**: Probability of drawing two aces from a deck without replacement."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Deck of cards: 4 aces, 52 cards\n",
                "prob_ace1 = 4 / 52\n",
                "prob_ace2_given_ace1 = 3 / 51\n",
                "prob_two_aces = prob_ace1 * prob_ace2_given_ace1\n",
                "print(f\"Probability of drawing two aces: {prob_two_aces:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3 Law of Total Probability and Bayes’ Theorem\n",
                "**Explanation**: The law of total probability breaks down probabilities over a partition. Bayes’ Theorem updates probabilities based on new evidence.\n",
                "\n",
                "**Math**:\n",
                "- Law of Total Probability: P(A) = Σ P(A|B_i) * P(B_i), where {B_i} is a partition\n",
                "- Bayes’ Theorem: P(A|B) = [P(B|A) * P(A)] / P(B)\n",
                "\n",
                "**Example**: Disease testing with sensitivity and specificity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Disease prevalence: 1%, sensitivity: 95%, specificity: 90%\n",
                "P_D = 0.01  # P(Disease)\n",
                "P_pos_D = 0.95  # P(Positive|Disease)\n",
                "P_pos_noD = 0.10  # P(Positive|No Disease)\n",
                "P_noD = 1 - P_D\n",
                "P_pos = P_pos_D * P_D + P_pos_noD * P_noD  # Law of Total Probability\n",
                "P_D_pos = (P_pos_D * P_D) / P_pos  # Bayes' Theorem\n",
                "print(f\"Probability of disease given positive test: {P_D_pos:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Random Variables\n",
                "### 2.1 Discrete and Continuous Random Variables\n",
                "**Explanation**: A random variable maps outcomes to numbers. Discrete variables have countable values; continuous variables have uncountable values.\n",
                "\n",
                "**Math**:\n",
                "- Discrete: P(X = x) (PMF)\n",
                "- Continuous: f(x) (PDF), where ∫ f(x) dx = 1\n",
                "\n",
                "**Example**: Discrete (dice roll) and continuous (normal distribution)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from scipy.stats import norm\n",
                "\n",
                "# Discrete: Dice roll PMF\n",
                "x_discrete = np.array([1, 2, 3, 4, 5, 6])\n",
                "p_discrete = np.array([1/6] * 6)\n",
                "plt.stem(x_discrete, p_discrete, label='PMF (Dice)')\n",
                "\n",
                "# Continuous: Normal PDF\n",
                "x_continuous = np.linspace(-3, 3, 100)\n",
                "pdf = norm.pdf(x_continuous, 0, 1)\n",
                "plt.plot(x_continuous, pdf, label='PDF (Normal)')\n",
                "plt.title('Discrete vs Continuous Random Variables')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Expectation and Variance\n",
                "**Explanation**: Expectation measures the average outcome; variance measures spread.\n",
                "\n",
                "**Math**:\n",
                "- Expectation: E[X] = Σ x * P(X = x) (discrete), E[X] = ∫ x * f(x) dx (continuous)\n",
                "- Variance: Var(X) = E[(X - E[X])²] = E[X²] - (E[X])²\n",
                "\n",
                "**Example**: Expectation and variance of a binomial distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import binom\n",
                "\n",
                "n, p = 10, 0.5  # 10 trials, 50% success probability\n",
                "mean = n * p\n",
                "variance = n * p * (1 - p)\n",
                "print(f\"Binomial Mean: {mean}\")\n",
                "print(f\"Binomial Variance: {variance}\")\n",
                "\n",
                "# Visualize\n",
                "k = np.arange(0, n+1)\n",
                "pmf = binom.pmf(k, n, p)\n",
                "plt.stem(k, pmf)\n",
                "plt.title('Binomial Distribution PMF')\n",
                "plt.xlabel('k')\n",
                "plt.ylabel('Probability')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Common Probability Distributions\n",
                "### 3.1 Discrete Distributions\n",
                "#### 3.1.1 Bernoulli and Binomial\n",
                "**Explanation**: Bernoulli models a single trial with two outcomes; Binomial models multiple Bernoulli trials.\n",
                "\n",
                "**Math**:\n",
                "- Bernoulli: P(X = 1) = p, P(X = 0) = 1 - p\n",
                "- Binomial: P(X = k) = C(n, k) * p^k * (1-p)^(n-k)\n",
                "\n",
                "**Example**: Binomial distribution for coin flips."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Binomial: 10 coin flips, p=0.5\n",
                "n, p = 10, 0.5\n",
                "k = np.arange(0, n+1)\n",
                "pmf = binom.pmf(k, n, p)\n",
                "plt.stem(k, pmf)\n",
                "plt.title('Binomial PMF (n=10, p=0.5)')\n",
                "plt.xlabel('Number of Heads')\n",
                "plt.ylabel('Probability')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 3.1.2 Poisson\n",
                "**Explanation**: Models the number of events in a fixed interval.\n",
                "\n",
                "**Math**: P(X = k) = (λ^k * e^(-λ)) / k!, where λ is the average rate.\n",
                "\n",
                "**Example**: Number of customer arrivals in an hour."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import poisson\n",
                "\n",
                "lambda_ = 3  # Average 3 arrivals per hour\n",
                "k = np.arange(0, 10)\n",
                "pmf = poisson.pmf(k, lambda_)\n",
                "plt.stem(k, pmf)\n",
                "plt.title('Poisson PMF (λ=3)')\n",
                "plt.xlabel('Number of Arrivals')\n",
                "plt.ylabel('Probability')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 3.1.3 Geometric and Negative Binomial\n",
                "**Explanation**: Geometric models trials until first success; Negative Binomial models trials until r successes.\n",
                "\n",
                "**Math**:\n",
                "- Geometric: P(X = k) = (1-p)^(k-1) * p\n",
                "- Negative Binomial: P(X = k) = C(k-1, r-1) * p^r * (1-p)^(k-r)\n",
                "\n",
                "**Example**: Geometric distribution for trials until success."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import geom\n",
                "\n",
                "p = 0.3\n",
                "k = np.arange(1, 10)\n",
                "pmf = geom.pmf(k, p)\n",
                "plt.stem(k, pmf)\n",
                "plt.title('Geometric PMF (p=0.3)')\n",
                "plt.xlabel('Trials Until Success')\n",
                "plt.ylabel('Probability')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Continuous Distributions\n",
                "#### 3.2.1 Normal (Gaussian)\n",
                "**Explanation**: Models data with a bell-shaped curve, central to many statistical methods.\n",
                "\n",
                "** Dark Mode: **Math**: f(x) = (1/√(2πσ²)) * e^(-(x-μ)²/(2σ²))\n",
                "\n",
                "**Example**: Normal distribution visualization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mu, sigma = 0, 1\n",
                "x = np.linspace(-3, 3, 100)\n",
                "pdf = norm.pdf(x, mu, sigma)\n",
                "plt.plot(x, pdf)\n",
                "plt.title('Normal PDF (μ=0, σ=1)')\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Density')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 3.2.2 Exponential\n",
                "**Explanation**: Models time between events in a Poisson process.\n",
                "\n",
                "**Math**: f(x) = λ * e^(-λx), x ≥ 0\n",
                "\n",
                "**Example**: Time between customer arrivals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import expon\n",
                "\n",
                "lambda_ = 1/2  # Mean time = 2 units\n",
                "x = np.linspace(0, 10, 100)\n",
                "pdf = expon.pdf(x, scale=1/lambda_)\n",
                "plt.plot(x, pdf)\n",
                "plt.title('Exponential PDF (λ=0.5)')\n",
                "plt.xlabel('Time')\n",
                "plt.ylabel('Density')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 3.2.3 Beta and Gamma\n",
                "**Explanation**: Beta models proportions; Gamma models waiting times for multiple events.\n",
                "\n",
                "**Math**:\n",
                "- Beta: f(x) = [x^(α-1) * (1-x)^(β-1)] / B(α, β), 0 ≤ x ≤ 1\n",
                "- Gamma: f(x) = [x^(k-1) * e^(-x/θ)] / [θ^k * Γ(k)]\n",
                "\n",
                "**Example**: Beta distribution for modeling proportions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import beta\n",
                "\n",
                "a, b = 2, 5\n",
                "x = np.linspace(0, 1, 100)\n",
                "pdf = beta.pdf(x, a, b)\n",
                "plt.plot(x, pdf)\n",
                "plt.title('Beta PDF (α=2, β=5)')\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Density')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 3.2.4 Uniform\n",
                "**Explanation**: Models equal probability over a range.\n",
                "\n",
                "**Math**: f(x) = 1/(b-a), a ≤ x ≤ b\n",
                "\n",
                "**Example**: Uniform distribution over [0, 1]."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import uniform\n",
                "\n",
                "x = np.linspace(-0.5, 1.5, 100)\n",
                "pdf = uniform.pdf(x, loc=0, scale=1)\n",
                "plt.plot(x, pdf)\n",
                "plt.title('Uniform PDF [0, 1]')\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Density')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Joint, Marginal, and Conditional Distributions\n",
                "**Explanation**: Joint distributions model multiple variables; marginals focus on one variable; conditionals model dependencies.\n",
                "\n",
                "**Math**:\n",
                "- Joint: P(X, Y) or f(x, y)\n",
                "- Marginal: P(X) = Σ_Y P(X, Y) (discrete), ∫ f(x, y) dy (continuous)\n",
                "- Conditional: P(X|Y) = P(X, Y) / P(Y)\n",
                "\n",
                "**Example**: Bivariate normal distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import multivariate_normal\n",
                "\n",
                "mean = [0, 0]\n",
                "cov = [[1, 0.5], [0.5, 1]]\n",
                "rv = multivariate_normal(mean, cov)\n",
                "x, y = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
                "pos = np.dstack((x, y))\n",
                "pdf = rv.pdf(pos)\n",
                "plt.contourf(x, y, pdf, cmap='viridis')\n",
                "plt.title('Bivariate Normal PDF')\n",
                "plt.xlabel('X')\n",
                "plt.ylabel('Y')\n",
                "plt.colorbar()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Covariance and Correlation\n",
                "**Explanation**: Measures the relationship between variables.\n",
                "\n",
                "**Math**:\n",
                "- Cov(X, Y) = E[(X - E[X])(Y - E[Y])]\n",
                "- Corr(X, Y) = Cov(X, Y) / (σ_X * σ_Y)\n",
                "\n",
                "**Example**: Correlation of two variables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "X = np.random.normal(0, 1, 100)\n",
                "Y = X + np.random.normal(0, 0.5, 100)\n",
                "cov = np.cov(X, Y)[0, 1]\n",
                "corr = np.corrcoef(X, Y)[0, 1]\n",
                "plt.scatter(X, Y)\n",
                "plt.title(f'Covariance: {cov:.2f}, Correlation: {corr:.2f}')\n",
                "plt.xlabel('X')\n",
                "plt.ylabel('Y')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Central Limit Theorem (CLT)\n",
                "**Explanation**: Sample means approximate a normal distribution for large n.\n",
                "\n",
                "**Math**: X̄ ~ N(μ, σ²/n) as n → ∞\n",
                "\n",
                "**Example**: Simulate sample means from a uniform distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "sample_means = [np.mean(np.random.uniform(0, 1, 30)) for _ in range(1000)]\n",
                "plt.hist(sample_means, bins=30, density=True)\n",
                "plt.title('CLT: Histogram of Sample Means')\n",
                "plt.xlabel('Sample Mean')\n",
                "plt.ylabel('Density')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Law of Large Numbers (LLN)\n",
                "**Explanation**: Sample average converges to population mean as n increases.\n",
                "\n",
                "**Math**: X̄ → μ as n → ∞\n",
                "\n",
                "**Example**: Demonstrate convergence of sample mean."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n = np.logspace(1, 5, 100, dtype=int)\n",
                "means = [np.mean(np.random.uniform(0, 1, n_i)) for n_i in n]\n",
                "plt.plot(n, means, label='Sample Mean')\n",
                "plt.axhline(0.5, color='r', linestyle='--', label='True Mean')\n",
                "plt.xscale('log')\n",
                "plt.title('LLN: Sample Mean Convergence')\n",
                "plt.xlabel('Sample Size (log scale)')\n",
                "plt.ylabel('Sample Mean')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Conditional Expectation and Variance\n",
                "**Explanation**: Expected value and variance given a condition.\n",
                "\n",
                "**Math**:\n",
                "- E[X|Y] = Σ x * P(X=x|Y) (discrete)\n",
                "- Var(X|Y) = E[X²|Y] - (E[X|Y])²\n",
                "\n",
                "**Example**: Conditional expectation in a bivariate normal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bivariate normal: E[X|Y=y] = μ_X + ρ * σ_X/σ_Y * (y - μ_Y)\n",
                "mu_x, mu_y, sigma_x, sigma_y, rho = 0, 0, 1, 1, 0.5\n",
                "y = 1\n",
                "cond_mean = mu_x + rho * sigma_x / sigma_y * (y - mu_y)\n",
                "print(f\"Conditional Expectation E[X|Y=1]: {cond_mean:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Markov Chains\n",
                "**Explanation**: Models state transitions with memoryless property.\n",
                "\n",
                "**Math**: P(X_{n+1} = j | X_n = i) = P_{ij} (transition probability)\n",
                "\n",
                "**Example**: Simple two-state Markov chain."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "P = np.array([[0.7, 0.3], [0.4, 0.6]])  # Transition matrix\n",
                "state = 0\n",
                "states = [state]\n",
                "np.random.seed(42)\n",
                "for _ in range(10):\n",
                "    state = np.random.choice([0, 1], p=P[state])\n",
                "    states.append(state)\n",
                "plt.plot(states, marker='o')\n",
                "plt.title('Markov Chain State Transitions')\n",
                "plt.xlabel('Step')\n",
                "plt.ylabel('State')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Bayesian Inference\n",
                "**Explanation**: Updates probabilities using Bayes’ Theorem.\n",
                "\n",
                "**Math**: P(θ|D) = [P(D|θ) * P(θ)] / P(D)\n",
                "\n",
                "**Example**: Bayesian update for coin bias."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import beta\n",
                "\n",
                "prior_a, prior_b = 1, 1  # Uniform prior\n",
                "heads, trials = 7, 10\n",
                "post_a, post_b = prior_a + heads, prior_b + trials - heads\n",
                "x = np.linspace(0, 1, 100)\n",
                "plt.plot(x, beta.pdf(x, prior_a, prior_b), label='Prior')\n",
                "plt.plot(x, beta.pdf(x, post_a, post_b), label='Posterior')\n",
                "plt.title('Bayesian Inference: Coin Bias')\n",
                "plt.xlabel('p')\n",
                "plt.ylabel('Density')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Monte Carlo Methods\n",
                "**Explanation**: Uses random sampling to estimate probabilities or integrals.\n",
                "\n",
                "**Math**: E[g(X)] ≈ (1/n) * Σ g(X_i), X_i ~ f(x)\n",
                "\n",
                "**Example**: Estimate π using Monte Carlo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n = 10000\n",
                "points = np.random.uniform(-1, 1, (n, 2))\n",
                "inside = np.sum(points[:, 0]**2 + points[:, 1]**2 <= 1)\n",
                "pi_est = 4 * inside / n\n",
                "print(f\"Estimated π: {pi_est:.4f}\")\n",
                "plt.scatter(points[:, 0], points[:, 1], c=np.where(points[:, 0]**2 + points[:, 1]**2 <= 1, 'b', 'r'), s=1)\n",
                "plt.title('Monte Carlo Estimation of π')\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('y')\n",
                "plt.gca().set_aspect('equal')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Hypothesis Testing and P-Values\n",
                "**Explanation**: Tests hypotheses using sample data; p-value measures evidence against null hypothesis.\n",
                "\n",
                "**Math**: p-value = P(data | H_0)\n",
                "\n",
                "**Example**: One-sample t-test."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import ttest_1samp\n",
                "\n",
                "np.random.seed(42)\n",
                "data = np.random.normal(0.1, 1, 30)\n",
                "t_stat, p_value = ttest_1samp(data, 0)\n",
                "print(f\"t-statistic: {t_stat:.2f}, p-value: {p_value:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Confidence Intervals\n",
                "**Explanation**: Range of values likely to contain the population parameter.\n",
                "\n",
                "**Math**: CI = X̄ ± z * (σ/√n)\n",
                "\n",
                "**Example**: Confidence interval for sample mean."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import norm\n",
                "\n",
                "np.random.seed(42)\n",
                "data = np.random.normal(0, 1, 30)\n",
                "mean = np.mean(data)\n",
                "std = np.std(data, ddof=1)\n",
                "z = norm.ppf(0.975)  # 95% CI\n",
                "ci_lower = mean - z * std / np.sqrt(30)\n",
                "ci_upper = mean + z * std / np.sqrt(30)\n",
                "print(f\"95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. Maximum Likelihood Estimation (MLE)\n",
                "**Explanation**: Estimates parameters by maximizing likelihood.\n",
                "\n",
                "**Math**: L(θ) = Π f(x_i | θ), θ̂ = argmax L(θ)\n",
                "\n",
                "**Example**: MLE for normal distribution mean."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "data = np.random.normal(5, 1, 100)\n",
                "mu_mle = np.mean(data)\n",
                "print(f\"MLE for mean: {mu_mle:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 15. Information Theory\n",
                "**Explanation**: Quantifies information in probabilistic systems.\n",
                "\n",
                "**Math**:\n",
                "- Entropy: H(X) = -Σ P(x) * log P(x)\n",
                "- Mutual Information: I(X;Y) = H(X) - H(X|Y)\n",
                "\n",
                "**Example**: Entropy of a Bernoulli variable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import entropy\n",
                "\n",
                "p = [0.3, 0.7]\n",
                "H = entropy(p, base=2)\n",
                "print(f\"Entropy: {H:.2f} bits\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 16. Multivariate Distributions\n",
                "### 16.1 Multivariate Normal\n",
                "**Explanation**: Generalizes normal distribution to multiple dimensions.\n",
                "\n",
                "**Math**: f(x) = (2π)^(-k/2) |Σ|^(-1/2) * e^(-1/2 (x-μ)^T Σ^(-1) (x-μ))\n",
                "\n",
                "**Example**: Already shown in Joint Distributions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 16.2 Copulas\n",
                "**Explanation**: Models dependencies between variables with different marginals.\n",
                "\n",
                "**Math**: C(u_1, u_2) = P(U_1 ≤ u_1, U_2 ≤ u_2), where U_i are uniform\n",
                "\n",
                "**Example**: Gaussian copula."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import multivariate_normal, norm\n",
                "\n",
                "np.random.seed(42)\n",
                "rho = 0.5\n",
                "mvn = multivariate_normal([0, 0], [[1, rho], [rho, 1]])\n",
                "u = norm.cdf(mvn.rvs(1000))\n",
                "plt.scatter(u[:, 0], u[:, 1])\n",
                "plt.title('Gaussian Copula Samples')\n",
                "plt.xlabel('U_1')\n",
                "plt.ylabel('U_2')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 17. Stochastic Processes\n",
                "### 17.1 Poisson Process\n",
                "**Explanation**: Models event occurrences over time.\n",
                "\n",
                "**Math**: N(t) ~ Poisson(λt)\n",
                "\n",
                "**Example**: Simulate Poisson process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "lambda_ = 2\n",
                "t = np.cumsum(np.random.exponential(1/lambda_, 20))\n",
                "plt.step(t, np.arange(1, 21), where='post')\n",
                "plt.title('Poisson Process')\n",
                "plt.xlabel('Time')\n",
                "plt.ylabel('Number of Events')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 17.2 Brownian Motion\n",
                "**Explanation**: Models continuous random walks.\n",
                "\n",
                "**Math**: W(t) ~ N(0, t)\n",
                "\n",
                "**Example**: Simulate Brownian motion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n = 1000\n",
                "t = np.linspace(0, 1, n)\n",
                "W = np.cumsum(np.random.normal(0, np.sqrt(1/n), n))\n",
                "plt.plot(t, W)\n",
                "plt.title('Brownian Motion')\n",
                "plt.xlabel('Time')\n",
                "plt.ylabel('W(t)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 17.3 Hidden Markov Models (HMMs)\n",
                "**Explanation**: Models sequences with hidden states.\n",
                "\n",
                "**Math**: P(O, S) = P(S_1) * Π P(S_t|S_{t-1}) * P(O_t|S_t)\n",
                "\n",
                "**Example**: Simple HMM simulation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "trans = [[0.7, 0.3], [0.4, 0.6]]\n",
                "emit = [[0.9, 0.1], [0.2, 0.8]]\n",
                "states = [0]\n",
                "obs = [np.random.choice([0, 1], p=emit[0])]\n",
                "for _ in range(10):\n",
                "    state = np.random.choice([0, 1], p=trans[states[-1]])\n",
                "    obs.append(np.random.choice([0, 1], p=emit[state]))\n",
                "    states.append(state)\n",
                "plt.plot(states, label='Hidden States', marker='o')\n",
                "plt.plot(obs, label='Observations', marker='x')\n",
                "plt.title('HMM Simulation')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 18. Probability Inequalities\n",
                "**Explanation**: Bounds on probabilities.\n",
                "\n",
                "**Math**:\n",
                "- Markov’s: P(X ≥ a) ≤ E[X]/a, a > 0\n",
                "- Chebyshev’s: P(|X - μ| ≥ kσ) ≤ 1/k²\n",
                "\n",
                "**Example**: Chebyshev’s inequality for sample mean."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "data = np.random.normal(0, 1, 100)\n",
                "mean, std = np.mean(data), np.std(data, ddof=1)\n",
                "k = 2\n",
                "chebyshev_bound = 1 / k**2\n",
                "empirical = np.mean(np.abs(data - mean) >= k * std)\n",
                "print(f\"Chebyshev bound: {chebyshev_bound:.4f}, Empirical: {empirical:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 19. Causal Inference and Propensity Scores\n",
                "**Explanation**: Estimates causal effects using probability.\n",
                "\n",
                "**Math**: P(Treatment | Covariates) (propensity score)\n",
                "\n",
                "**Example**: Simulate propensity score calculation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "np.random.seed(42)\n",
                "X = np.random.normal(0, 1, (100, 2))\n",
                "T = (X[:, 0] + np.random.normal(0, 0.5, 100) > 0).astype(int)\n",
                "model = LogisticRegression().fit(X, T)\n",
                "prop_scores = model.predict_proba(X)[:, 1]\n",
                "plt.hist(prop_scores, bins=20)\n",
                "plt.title('Propensity Score Distribution')\n",
                "plt.xlabel('Propensity Score')\n",
                "plt.ylabel('Frequency')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 20. Mixture Models\n",
                "**Explanation**: Combines multiple distributions.\n",
                "\n",
                "**Math**: f(x) = Σ π_k * f_k(x), Σ π_k = 1\n",
                "\n",
                "**Example**: Gaussian Mixture Model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.mixture import GaussianMixture\n",
                "\n",
                "np.random.seed(42)\n",
                "X = np.concatenate([np.random.normal(-2, 1, 200), np.random.normal(2, 1, 200)]).reshape(-1, 1)\n",
                "gmm = GaussianMixture(n_components=2).fit(X)\n",
                "x = np.linspace(-5, 5, 100).reshape(-1, 1)\n",
                "logprob = gmm.score_samples(x)\n",
                "plt.hist(X, bins=30, density=True, alpha=0.5)\n",
                "plt.plot(x, np.exp(logprob), label='GMM')\n",
                "plt.title('Gaussian Mixture Model')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 21. Empirical Bayes Methods\n",
                "**Explanation**: Uses data to inform priors in Bayesian inference.\n",
                "\n",
                "**Math**: Estimate prior parameters from data, then apply Bayes’ Theorem.\n",
                "\n",
                "**Example**: Empirical Bayes for binomial data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "data = np.random.binomial(10, 0.3, 50)\n",
                "prior_a = np.mean(data) / np.var(data)\n",
                "prior_b = (1 - np.mean(data) / 10) * prior_a\n",
                "post_a = prior_a + np.sum(data)\n",
                "post_b = prior_b + 50 * 10 - np.sum(data)\n",
                "x = np.linspace(0, 1, 100)\n",
                "plt.plot(x, beta.pdf(x, prior_a, prior_b), label='Empirical Prior')\n",
                "plt.plot(x, beta.pdf(x, post_a, post_b), label='Posterior')\n",
                "plt.title('Empirical Bayes')\n",
                "plt.xlabel('p')\n",
                "plt.ylabel('Density')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 22. Probability in Graphical Models\n",
                "**Explanation**: Models dependencies using graphs (e.g., Bayesian networks).\n",
                "\n",
                "**Math**: P(X_1, ..., X_n) = Π P(X_i | Parents(X_i))\n",
                "\n",
                "**Example**: Simple Bayesian network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "P_A = 0.3\n",
                "P_B_A = [[0.8, 0.2], [0.4, 0.6]]\n",
                "A = np.random.binomial(1, P_A)\n",
                "B = np.random.binomial(1, P_B_A[A][1])\n",
                "print(f\"A: {A}, B: {B}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 23. Rare Event Analysis and Extreme Value Theory\n",
                "**Explanation**: Models low-probability, high-impact events.\n",
                "\n",
                "**Math**: Generalized Extreme Value (GEV) distribution\n",
                "\n",
                "**Example**: Fit GEV to maximum values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import genextreme\n",
                "\n",
                "np.random.seed(42)\n",
                "data = np.random.normal(0, 1, (100, 10)).max(axis=1)\n",
                "params = genextreme.fit(data)\n",
                "x = np.linspace(min(data), max(data), 100)\n",
                "plt.hist(data, bins=20, density=True, alpha=0.5)\n",
                "plt.plot(x, genextreme.pdf(x, *params), label='GEV')\n",
                "plt.title('Extreme Value Distribution')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 24. Sampling Methods\n",
                "### 24.1 Importance Sampling\n",
                "**Explanation**: Samples from a proposal distribution to estimate expectations.\n",
                "\n",
                "**Math**: E[g(X)] ≈ Σ w_i * g(X_i), w_i = f(X_i)/q(X_i)\n",
                "\n",
                "**Example**: Importance sampling for a normal distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "target = norm.pdf\n",
                "proposal = norm(loc=1, scale=2).rvs(1000)\n",
                "weights = target(proposal) / norm.pdf(proposal, loc=1, scale=2)\n",
                "est = np.mean(weights * (proposal > 0))\n",
                "print(f\"Estimated P(X > 0): {est:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 24.2 Markov Chain Monte Carlo (MCMC)\n",
                "**Explanation**: Samples from complex distributions using Markov chains.\n",
                "\n",
                "**Math**: Metropolis-Hastings acceptance probability\n",
                "\n",
                "**Example**: Metropolis-Hastings for normal distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "samples = [0.0]\n",
                "for _ in range(1000):\n",
                "    proposal = samples[-1] + np.random.normal(0, 1)\n",
                "    if np.random.uniform() < norm.pdf(proposal) / norm.pdf(samples[-1]):\n",
                "        samples.append(proposal)\n",
                "    else:\n",
                "        samples.append(samples[-1])\n",
                "plt.hist(samples, bins=30, downstairs=True)\n",
                "plt.title('MCMC: Normal Distribution')\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Frequency')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 25. Randomized Algorithms\n",
                "**Explanation**: Uses randomness for efficiency in algorithms.\n",
                "\n",
                "**Math**: Probabilistic guarantees on performance\n",
                "\n",
                "**Example**: Randomized selection algorithm."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "def quick_select(arr, k):\n",
                "    if len(arr) == 1:\n",
                "        return arr[0]\n",
                "    pivot = np.random.choice(arr)\n",
                "    left = arr[arr <= pivot]\n",
                "    right = arr[arr > pivot]\n",
                "    if k <= len(left):\n",
                "        return quick_select(left, k)\n",
                "    else:\n",
                "        return quick_select(right, k - len(left))\n",
                "arr = np.array([3, 8, 2, 5, 1, 4, 7, 6])\n",
                "k = 3\n",
                "result = quick_select(arr, k)\n",
                "print(f\"{k}th smallest element: {result}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}